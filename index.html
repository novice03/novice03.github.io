<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Pranav Pulijala</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!--
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    -->
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:35%;max-width:35%">
                <a href="images/profile.jpg"><img style="width:100%;max-width:100%;" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"></a>
              </td>
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Pranav Pulijala
                </p>
                <p>I'm a final-year undergraduate at the University of Wisconsin-Madison, majoring in Computer Science and Mathematics. </p>
                <p>I'm a research assistant in Dr. Vikas Singh's lab, where my work primarily focuses on transformer models. Our most recent work is LookupFFN (see publication below). My ongoing project leverages LLMs for neurodegenerative disease research. </p>
                <p>I enjoy open-source development - my contributions to Hugging Face (Swin Transformer, Nystromformer, YOSO, MRA, and EfficientFormer) have collectively gained over 1,000,000 downloads! </p>
                <p style="text-align:center">
                  <a href="mailto:pulijalapranav@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=upaJwwIAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/novice03/">Github</a>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in compute-efficiency and interdisciplinary applications of machine learning algorithms.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:20px;width:15%;vertical-align:middle">
                <img src="images/ffn_icon.png" alt="ffn_png" style="border-style: none; width: 200px;">
              </td>
              <td width="75%" valign="middle">
                <a href="https://icml.cc/virtual/2023/poster/25048">
                  <span class="papertitle">LookupFFN: Making Transformers Compute-lite for CPU inference</span>
                </a>
                <br>
                <a href="https://www.linkedin.com/in/zhanpeng-zeng-530692113/">Zhanpeng Zeng</a>,
                <a href="https://medav.github.io/">Michael Davies</a>,
                <strong>Pranav Pulijala</strong>,
                <a href="https://karu.sites.cs.wisc.edu/wiki/">Karthikeyan Sankaralingam</a>,
                <a href="https://www.biostat.wisc.edu/~vsingh/">Vikas Singh</a>
                <br>
                <em>ICML</em>, 2023
                <br>
                <p>While GPU clusters are the de facto choice for training large deep neural network (DNN) models today, several reasons including ease of workflow, security and cost have led to efforts investigating whether CPUs may be viable for inference in routine use in many sectors of the industry. 
                  But the imbalance between the compute capabilities of GPUs and CPUs is huge. Motivated by these considerations, we study a module which is a workhorse within modern DNN architectures, GEMM based Feed Forward Networks (FFNs), and assess the extent to which it can be made compute- (or FLOP-) lite. 
                  Specifically, we propose an alternative formulation (we call it LookupFFN) to GEMM based FFNs inspired by the recent studies of using Locality Sensitive Hashing (LSH) to approximate FFNs. Code is avaiable at <a href="https://github.com/mlpen/LookupFFN">github.com/mlpen/LookupFFN</a></p>
              </td>
            </tr>
          </table>
        </td>
      </tr>
    </table>
  </body>
</html>
